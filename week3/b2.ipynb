{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from time import process_time\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"banking.csv\")\n",
    "dict_month = {'jan' : 1, 'feb' : 2, 'mar' : 3, 'apr' : 4, 'may' : 5, 'jun' : 6,'jul' : 7, 'aug' : 8, 'sep' : 9, 'oct' : 10, 'nov' : 11, 'dec' : 12}\n",
    "\n",
    "data['month'] = data['month'].map(dict_month)\n",
    "# convert field of dayOfweek\n",
    "dict_day = {'sun' : 1, 'mon' : 2, 'tue' : 3, 'wed' : 4, 'thu' : 5, 'fri' : 6,\n",
    "'sat' : 7}\n",
    "data['day_of_week'] = data['day_of_week'].map(dict_day)\n",
    "# conver binary fields\n",
    "#default :\n",
    "data.default.replace({'no' : 0, 'yes' : 1}, inplace = True)\n",
    "#housing :\n",
    "data.housing.replace({'no' : 0, 'yes' : 1}, inplace = True)\n",
    "#loan :\n",
    "data.loan.replace({'no' : 0, 'yes' : 1}, inplace = True)\n",
    "# convert categories field by one host coding\n",
    "marital_dummies = pd.get_dummies(data['marital'], prefix = 'marital')\n",
    "marital_dummies.drop('marital_divorced', axis=1, inplace=True)\n",
    "data = pd.concat([data, marital_dummies], axis=1)\n",
    "job_dummies = pd.get_dummies(data['job'], prefix = 'job')\n",
    "job_dummies.drop('job_unknown', axis=1, inplace=True)\n",
    "data= pd.concat([data, job_dummies], axis=1)\n",
    "education_dummies = pd.get_dummies(data['education'], prefix = 'education')\n",
    "education_dummies.drop('education_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, education_dummies], axis=1)\n",
    "contact_dummies = pd.get_dummies(data['contact'], prefix = 'contact')\n",
    "#contact_dummies.drop('contact_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, contact_dummies], axis=1)\n",
    "poutcome_dummies = pd.get_dummies(data['poutcome'], prefix = 'poutcome')\n",
    "#poutcome_dummies.drop('poutcome_unknown', axis=1, inplace=True)\n",
    "data = pd.concat([data, poutcome_dummies], axis=1)\n",
    "data['pdays'] = data['pdays'].apply(lambda row: 0 if row == -1 else 1)\n",
    "data.drop(['job', 'education', 'marital', 'contact', 'poutcome'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = data[ (data['housing'] == 'unknown') & (data['loan'] == 'unknown') ].index\n",
    "data.drop(index, inplace=True)\n",
    "# data.housing.replace({'unknown': 0}, inplace=True)\n",
    "# data.loan.replace({'unknown': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.default.replace({'unknown': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default\n",
       "0    40195\n",
       "1        3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = data.groupby('default').size()\n",
    "# p['unknown'] / (p[0] + p[1] + p['unknown'])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sau khi có dữ liệu thuần số, hãy chia dữ liệu thành phần Training và phần Test theo tỷ lệ 8:2, trong đó với phần Test, trường y sẽ không dùng đến."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'y'\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sử dụng mô hình hồi quy logistic với phần dữ liệu Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\APP\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "cls = LogisticRegression()\n",
    "start1 = process_time()\n",
    "cls.fit(X_train, y_train)\n",
    "end1 = process_time()\n",
    "print(end1 - start1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dự đoán và tính metrics (Logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      7139\n",
      "           1       0.65      0.35      0.46       901\n",
      "\n",
      "    accuracy                           0.91      8040\n",
      "   macro avg       0.79      0.66      0.70      8040\n",
      "weighted avg       0.89      0.91      0.89      8040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = cls.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>khong dang ky</th>\n",
       "      <th>co dang ky</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Khong dang ky</th>\n",
       "      <td>6967</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co dang ky</th>\n",
       "      <td>584</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               khong dang ky  co dang ky\n",
       "Khong dang ky           6967         172\n",
       "co dang ky               584         317"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0, 1]))\n",
    "confusion = pd.DataFrame(cm, index=[\"Khong dang ky\", \"co dang ky\"], columns=[\"khong dang ky\", \"co dang ky\"])\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sử dụng mô hình Naïve Bayes phù hợp với tập huấn luyện như trên, sau đó chạy dự đoán với tập Test và tính độ chính xác của mô hình, như ý a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015625\n"
     ]
    }
   ],
   "source": [
    "cls = GaussianNB()\n",
    "start2 = process_time()\n",
    "cls.fit(X_train, y_train)\n",
    "end2 = process_time()\n",
    "print(end2 - start2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dự đoán và tính metrics (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      7139\n",
      "           1       0.33      0.57      0.42       901\n",
      "\n",
      "    accuracy                           0.82      8040\n",
      "   macro avg       0.64      0.71      0.66      8040\n",
      "weighted avg       0.87      0.82      0.84      8040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict = cls.predict(X_test)\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So sánh thời gian chạy cũng như độ chính xác của hai phương pháp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thời gian chạy phương pháp:\n",
    "- Logistic regression: 0.09375 (s)\n",
    "- Naive Bayes: 0.015625 (s)\n",
    "\n",
    "Độ chính xác:\n",
    "- Logistic regression: 0.91\n",
    "- Naive Bayes: 0.82\n",
    "\n",
    "=> \n",
    "- Logistic regression có độ chính xác cao hơn.\n",
    "- Naive bayes nhanh hơn.\n",
    "- Precision và recall của cả 2 phương pháp đối với class `1` đều thấp, đối với class `0` thì cao, do chưa có bước xử lý dữ liệu không cân bằng."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
